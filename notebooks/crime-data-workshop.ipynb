{"nbformat_minor": 1, "cells": [{"source": "# Explore UK Crime Data with Pandas and GeoPandas\n\n\n## Table of Contents\n\n1. [Introduction to Pandas](#pandas)<br>\n2. [Introduction to GeoPandas](#geopandas)<br>\n3. [Getting ready](#ready)<br>\n4. [London boroughs](#boroughs)<br>\n    4.1. [Load data](#load1)<br>\n    4.2. [Explore data](#explore1)<br>\n5. [Crime data](#crime)<br>\n    5.1. [Load data](#load2)<br>\n    5.2. [Explore data](#explore2)<br>", "cell_type": "markdown", "metadata": {}}, {"source": "import pandas as pd\nimport geopandas as gpd\nimport numpy as np\nfrom shapely.geometry import Point, LineString, Polygon\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\n%matplotlib inline", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "<a id=\"pandas\"></a>\n## 1. Introduction to Pandas\n\n<div class=\"alert alert-info\" style=\"font-size:100%\">\n  <b>This intro is very brief, with just enough info to get you started with exploring Pandas. Only a few functions are used here, there are many many more to explore! Read this <a href=\"http://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html\">10 minute introduction</a> for a bit more detailed overview of Pandas. Or check out <a href=\"https://jakevdp.github.io/PythonDataScienceHandbook/\">this book</a>.<br>\n</div>    \n\n<a id=\"series\"></a>\n### 1.1 Series and DataFrames \n\nLet's start with the basics of Pandas. Pandas has two main data structures: `Series` and `DataFrames`. \n\nA `Series` is a list of values with an integer index. The first column is the index (the default starts at 0) and the second column the values.", "cell_type": "markdown", "metadata": {}}, {"source": "s = pd.Series([1, 3, 5, np.nan, 6, 8])\ns", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "A `DataFrame` is similar, but has multiple columns. You can create one in many ways, by loading a file or from for example a NumPy array and a date for the index. (We come back to the index and dates later) \n\n\n<div class=\"alert alert-info\" style=\"font-size:100%\">\n<b>To do later: read this <a href=\"https://docs.scipy.org/doc/numpy-1.15.0/user/quickstart.html\"> tutorial</a> for an overview of NumPy.<br>\n</div>\n\nTwo examples:", "cell_type": "markdown", "metadata": {}}, {"source": "dates = pd.date_range('20130101', periods=6)\nnumbers = np.random.randn(6, 4)\ndf1 = pd.DataFrame(numbers, index=dates, columns=list('ABCD'))\ndf1", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "df2 = pd.DataFrame({'A': 1.,\n                     'B': pd.Timestamp('20130102'),\n                     'C': pd.Series(1, index=list(range(4)), dtype='float32'),\n                     'D': np.array([3] * 4, dtype='int32'),\n                     'E': pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n                     'F': 'foo'})\ndf2", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "To find out what the data type is of a variable use `type()` with the variable in between the brackets: ", "cell_type": "markdown", "metadata": {}}, {"source": "type(s)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "type(dates)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "type(numbers)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "type(df1)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "<a id=\"selection\"></a>\n### 1.2 Data Selection\n\nFor this we will create a new DataFrame with the population of the 5 largest cities in the UK ([source](https://en.wikipedia.org/wiki/List_of_urban_areas_in_the_United_Kingdom)). `data` is a [dictionary](https://realpython.com/python-dicts/).", "cell_type": "markdown", "metadata": {}}, {"source": "cities = pd.DataFrame({'city':       ['London','Manchester','Birmingham','Leeds','Glasgow'],\n        'population': [9787426,  2553379,     2440986,    1777934, 1209143],\n        'area':       [1737.9,   630.3,       598.9,      487.8,   368.5 ],\n        'latitude':   [51.50853, 53.48095,    52.48142,   53.79648,55.86515],\n        'longitude':  [-0.12574, -2.23743,    -1.89983,   -1.54785,-4.25763]})\ncities", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "cities.iloc[0]", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "cities.iloc[:,1]", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "cities.iloc[:,0:2]", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "#### Filtering\n\nSelecting rows based on a certain condition can be done with Boolean indexing:", "cell_type": "markdown", "metadata": {}}, {"source": "cities['area'] > 500", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "If you want to select the data add `cities[]` around the above:", "cell_type": "markdown", "metadata": {}}, {"source": "cities[cities['area'] > 500]", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Combining different columns using `&`, `|` and `==` is also possible\"", "cell_type": "markdown", "metadata": {}}, {"source": "cities[(cities['area'] > 500) & (cities['population'] > 2500000)]", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "cities[(cities['area'] < 500) | (cities['population'] < 1000000)]", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "cities[cities['area'] == 487.8] ", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "<a id=\"transform\"></a>\n### 1.3. Transform Data\n\nWhen looking at data there are always transformations needed to get it in the format you need for your analysis, visualisations or models. \n\nThese are a few examples of the endless possibilities. The best way to learn is to find a dataset and try to answer questions with the data. The Pandas documentation is real good, and on StackOverflow there is almost always someone who asked the same question already. \n\n<a id=\"columns\"></a>\n#### Adding and deleting columns\nAdding a column can be done by defining a new column, which can then be dropped with 'drop'. ", "cell_type": "markdown", "metadata": {}}, {"source": "cities['new'] = 1\ncities", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "cities = cities.drop(columns='new')\ncities", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "cities['density'] = cities.population / cities.area\ncities", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "<a id=\"merging\"></a>\n#### Merging Data\n\nThere are several ways to combine data. The [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) has lots of examples. You can combine data with `.append()` or `.concat()`:", "cell_type": "markdown", "metadata": {}}, {"source": "data = {'city':       ['London','Manchester','Birmingham','Leeds','Glasgow'],\n        'population': [9787426,  2553379,     2440986,    1777934,1209143],\n        'area':       [1737.9,   630.3,       598.9,      487.8,  368.5 ]}\ncities = pd.DataFrame(data)\n\ndata2 = {'city':       ['Liverpool','Southampton'],\n        'population': [864122,  855569],\n        'area':       [199.6,   192.0]}\ncities2 = pd.DataFrame(data2)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "These new cities can be added with `append()`:", "cell_type": "markdown", "metadata": {}}, {"source": "cities = cities.append(cities2).reset_index()\ncities", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "data = {'city': ['London','Manchester','Birmingham','Leeds','Glasgow'],\n        'density': [5630,4051,4076,3645,3390]}\ncities3 = pd.DataFrame(data)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "cities3", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "An extra column can be added with `.merge()` with an outer join using the city names:", "cell_type": "markdown", "metadata": {}}, {"source": "cities = pd.merge(cities, cities3, how='outer', sort=True,on='city')\ncities", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "<a id=\"plotting\"></a>\n#### Plotting Data\n\nThe data in a DataFrame can be easily plotted. These are just a few small examples, later in the workshop there will be many more. \n\nThe default is a line chart:", "cell_type": "markdown", "metadata": {}}, {"source": "cities['population'].plot();", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "To create a plot that makes more sense for this data have a look at the [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html) for all options. A bar chart might work better:", "cell_type": "markdown", "metadata": {}}, {"source": "cities.plot.bar(x='city', y='population')", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "<a id=\"geopandas\"></a>\n## 2. Introduction to GeoPandas\n\nA GeoDataSeries or GeoDataFrame is very similar to a Pandas DataFrame, but has an additional column with the geometry. You can load a file, or create your own:", "cell_type": "markdown", "metadata": {}}, {"source": "df = pd.DataFrame({'city':       ['London','Manchester','Birmingham','Leeds','Glasgow'],\n        'population': [9787426,  2553379,     2440986,    1777934, 1209143],\n        'area':       [1737.9,   630.3,       598.9,      487.8,   368.5 ],\n        'latitude':   [51.50853, 53.48095,    52.48142,   53.79648,55.86515],\n        'longitude':  [-0.12574, -2.23743,    -1.89983,   -1.54785,-4.25763]})\n\ndf['geometry']  = list(zip(df.longitude, df.latitude))\n\ndf['geometry'] = df['geometry'].apply(Point)\n\ncities = gpd.GeoDataFrame(df, geometry='geometry')\ncities.head()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Creating a basic map is similar to creating a plot from a Pandas DataFrame:", "cell_type": "markdown", "metadata": {}}, {"source": "cities.plot(column='population');", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "As `cities` is a DataFrame you can apply data manipulations, for instance:", "cell_type": "markdown", "metadata": {}}, {"source": "cities['population'].mean()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Let's create a lines between 2 cities, and circles around some of the cities and store them as polygons:", "cell_type": "markdown", "metadata": {}}, {"source": "london = cities.loc[cities['city'] == 'London', 'geometry'].squeeze()\nmanchester = cities.loc[cities['city'] == 'Manchester', 'geometry'].squeeze()\n\nline = gpd.GeoSeries(LineString([london, manchester]))\nline.plot();", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "cities2 = cities.copy()\ncities2['geometry'] = cities2.buffer(1)\ncities2 = cities2.drop([1, 2])\ncities2.head()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "cities2.plot();", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "And plot all of them together:", "cell_type": "markdown", "metadata": {}}, {"source": "base = cities2.plot(color='lightblue', edgecolor='black')\ncities.plot(ax=base, marker='o', color='red', markersize=10);\nline.plot(ax=base);", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "cities3 = cities.copy()\ncities3['geometry'] = cities3.buffer(2)\ncities3 = cities3.drop([1, 2])\n\ngpd.overlay(cities3, cities2, how='difference').plot();", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "In case you wondered how to change the size of the circles based on the population, Jeff Hemmen found a way in a previous workshop and tweeted his [solution](https://twitter.com/JeffHemmen/status/1125849422397607937):", "cell_type": "markdown", "metadata": {}}, {"source": "cities2['geometry'] = cities2.apply(lambda x: x['geometry'].buffer(x['population'] / 10000000), axis=1)\ncities2.plot();", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "### Spatial relationships\n\nThere are several functions to check geospatial relationships: `equals`, `contains`, `crosses`, `disjoint`,`intersects`,`overlaps`,`touches`,`within` and `covers`. These all use `shapely`: read more [here](https://shapely.readthedocs.io/en/stable/manual.html#predicates-and-relationships) and some more background [here](https://en.wikipedia.org/wiki/Spatial_relation).\n\nA few examples:", "cell_type": "markdown", "metadata": {}}, {"source": "cities2.contains(london)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "cities2[cities2.contains(london)]", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "cities2[cities2.contains(manchester)]", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "The inverse of `contains`:", "cell_type": "markdown", "metadata": {}}, {"source": "cities[cities.within(cities2)]", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "cities2[cities2.crosses(line)]", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "cities2[cities2.disjoint(london)]", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "<a id=\"ready\"></a>\n## 3. Getting ready\n\n### 3.1. Add data to Cloud Object Store (COS)\nThe data for this workshop needs to be added to your project. Go to the GitHub repo and download the files in the [data folder](https://github.com/IBMDeveloperUK/crime-data-workshop/tree/master/data) to your machine. \n\nAdd the files in the data menu on the right of the notebook (click the 1010 button  at the top right if you do not see this) into COS:\n\n- boundaries.zip\n- 2018-1-metropolitan-street.zip\n- 2018-2-metropolitan-street.zip\n- 2018-metropolitan-stop-and-search.zip\n", "cell_type": "markdown", "metadata": {}}, {"source": "### 3.2. Project Access token\n\nAs the data files are not simple csv files, we need a little trick to load the data. The first thing you need is a project access token to programmatically access COS.\n\nClick the 3 dots at the top of the notebook to insert the project token that you created earlier. This will create a new cell in the notebook that you will need to run first before continuing with the rest of the notebook. If you are sharing this notebook you should remove this cell, else anyone can use you Cloud Object Storage from this project.\n\n> If you cannot find the new cell it is probably at the top of this notebook. Scroll up, run the cell and continue with section 3.3", "cell_type": "markdown", "metadata": {}}, {"source": "### 3.3. Helper function to load data into notebook\n\nThe second thing you need to load data into the notebook is the below help function. Data will be copied to the local project space and loaded from there. The below helper function will do this for you. ", "cell_type": "markdown", "metadata": {}}, {"source": "# define the helper function \ndef download_file_to_local(project_filename, local_file_destination=None, project=None):\n    \"\"\"\n    Uses project-lib to get a bytearray and then downloads this file to local.\n    Requires a valid `project` object.\n    \n    Args:\n        project_filename str: the filename to be passed to get_file\n        local_file_destination: the filename for the local file if different\n        \n    Returns:\n        0 if everything worked\n    \"\"\"\n    \n    project = project\n    \n    # get the file\n    print(\"Attempting to get file {}\".format(project_filename))\n    _bytes = project.get_file(project_filename).read()\n    \n    # check for new file name, download the file\n    print(\"Downloading...\")\n    if local_file_destination==None: local_file_destination = project_filename\n    \n    with open(local_file_destination, 'wb') as f: \n        f.write(bytearray(_bytes))\n        print(\"Completed writing to {}\".format(local_file_destination))\n        \n    return 0", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "<a id=\"boroughs\"></a>\n## 4. London boroughs\n\nThere are various data sources out there, but [this one](https://data.london.gov.uk/dataset/2011-boundary-files) seemed most suitable as it contains a little more data than just the boundaries of the boroughs. A few files were combined together in the [data preparation notebook](https://github.com/IBMDeveloperUK/geopandas-workshop/blob/master/notebooks/prepare-uk-crime-data.ipynb), which makes this data quicker to load. \n\n<a id=\"load1\"></a>\n### 4.1. Load data\n\nLoading a shape file is easy with the use of the helper function from above that downloads the file to the local project space, and the `read_file` function from geopandas:", "cell_type": "markdown", "metadata": {}}, {"source": "download_file_to_local('boundaries.zip', project=project)\nboroughs = gpd.read_file(\"zip://./boundaries.zip\")\n!rm boundaries.zip\nboroughs.head()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "<a id=\"explore1\"></a>\n### 4.2. Explore data", "cell_type": "markdown", "metadata": {}}, {"source": "To plot a basic map add `.plot()` to a geoDataFrame.    ", "cell_type": "markdown", "metadata": {}}, {"source": "boroughs.plot();", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "LAD is Local Authority District. Adding a column will colour the map based on the classes in this column:", "cell_type": "markdown", "metadata": {}}, {"source": "boroughs.plot(column='LAD11CD');", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "The boroughs are made up of many districts that you might want to combine. This can be done with `.dissolve()`:", "cell_type": "markdown", "metadata": {}}, {"source": "lad = boroughs.dissolve(by='LAD11CD',aggfunc='sum')\nlad.head()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "lad.plot(column='HHOLDS');", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "<div class=\"alert alert-success\">\n <b>EXERCISE</b> <br/> \n Explore the data:\n  <ul>\n  <li>Create a map of number of households (HHOLDS) by Middle-Level Super Output Area (MSOA11CD)</li>\n  <li>Change the colors with the <font face=\"Courier\">cmap</font> option. Pick one of the colourmaps from https://matplotlib.org/users/colormaps.html</li>\n  <li>Add a legend with <font face=\"Courier\">legend=True</font></li>\n </ul> \n</div>  ", "cell_type": "markdown", "metadata": {}}, {"source": "# your answer (add as many cells as you need)\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Hopefully your map is starting to look nice now! Remember these options, as you will need them again. ", "cell_type": "markdown", "metadata": {}}, {"source": "To see what I have come up with, uncomment the next two cells and run the cell to load the answer. Then run the cell once more to run the code. You will see that there are many more options to customize your map. These [matplotlib tutorials](https://matplotlib.org/tutorials/index.html) go through many more options.", "cell_type": "markdown", "metadata": {}}, {"source": "# %load https://raw.githubusercontent.com/IBMDeveloperUK/crime-data-workshop/master/answers/answer1.py", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# %load https://raw.githubusercontent.com/IBMDeveloperUK/crime-data-workshop/master/answers/answer2.py", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "## Coordinate system\n\nBefore moving on let's check the coordinate systems of the different data sets. They need to be the same to use them together. Check the range of coordinates with `.total_bounds`: \n", "cell_type": "markdown", "metadata": {}}, {"source": "xmin, ymin, xmax, ymax = lad.total_bounds\nprint(xmin, ymin, xmax, ymax)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "The coordinate reference system (CRS) determines how the two-dimensional (planar) coordinates of the geometry objects should be related to actual places on the (non-planar) earth.", "cell_type": "markdown", "metadata": {}}, {"source": "lad.crs", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "These coordinates seem to be from the [National Grid](https://www.ordnancesurvey.co.uk/support/the-national-grid.html). If you want to learn more about coordinate systems, [this document](https://www.bnhs.co.uk/focuson/grabagridref/html/OSGB.pdf) from the Ordnance Survey gives a detailed overview.\n\nLet's also quickly read one of the files with crime data to check the coordinates. This is a Pandas DataFrame so you cannot check the bounding box, but from the table below it is clear that the coordinates are different, they are latitudes and longitudes (Greenwich is 51.4934\u00b0 N, 0.0098\u00b0 E). ", "cell_type": "markdown", "metadata": {}}, {"source": "download_file_to_local('2018-metropolitan-stop-and-search.zip', project=project)\nstop_search = pd.read_csv(\"./2018-metropolitan-stop-and-search.zip\")\n!rm 2018-metropolitan-stop-and-search.zip\nstop_search.head()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "It is possible to convert coordinates to a different system, but that is beyond the scope of this workshop. \n\nInstead let's just find another map in the right coordinates. This [json file](https://skgrange.github.io/www/data/london_boroughs.json) is exactly what we need and it can be read directly from the url:", "cell_type": "markdown", "metadata": {}}, {"source": "boroughs2 = gpd.read_file(\"https://skgrange.github.io/www/data/london_boroughs.json\")\nboroughs2.head()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "boroughs2.plot();", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "<a id=\"crime\"></a>\n## 5. Crime data\n\nThe crime data is pre-processed in this [notebook](https://github.com/IBMDeveloperUK/geopandas-workshop/blob/master/notebooks/prepare-uk-crime-data.ipynb) so it is easier to read here. We will only look at data from 2018.\n\nData is downloaded from https://data.police.uk/ ([License](https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/))\n\n<a id=\"load2\"></a>\n### 5.1. Load data\n\nThis dataset cannot be loaded into a geoDataFrame directly. Instead the data is loaded into a DataFrame and then converted:", "cell_type": "markdown", "metadata": {}}, {"source": "download_file_to_local('2018-1-metropolitan-street.zip', project=project)\ndownload_file_to_local('2018-2-metropolitan-street.zip', project=project)\nstreet = pd.read_csv(\"./2018-1-metropolitan-street.zip\")\nstreet2 = pd.read_csv(\"./2018-2-metropolitan-street.zip\")\nstreet = street.append(street2) ", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "download_file_to_local('2018-metropolitan-stop-and-search.zip', project=project)\nstop_search = pd.read_csv(\"./2018-metropolitan-stop-and-search.zip\")", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Clean up of the local directory:", "cell_type": "markdown", "metadata": {}}, {"source": "! rm *.zip", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "street.head()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "stop_search.head()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "#### Convert to geoDataFrames", "cell_type": "markdown", "metadata": {}}, {"source": "street['coordinates'] = list(zip(street.Longitude, street.Latitude))\nstreet['coordinates'] = street['coordinates'].apply(Point)\nstreet = gpd.GeoDataFrame(street, geometry='coordinates')\nstreet.head()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "stop_search['coordinates'] = list(zip(stop_search.Longitude, stop_search.Latitude))\nstop_search['coordinates'] = stop_search['coordinates'].apply(Point)\nstop_search = gpd.GeoDataFrame(stop_search, geometry='coordinates')\nstop_search.head()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "<a id=\"explore2\"></a>\n### 5.2. Explore data\n", "cell_type": "markdown", "metadata": {}}, {"source": "<div class=\"alert alert-success\">\n <b>EXERCISE</b> <br/> \n Explore the data with Pandas. There are no right or wrong answers, the questions below give you some suggestions at what to look at. <br/> \n   <ul>\n  <li>How much data is there? Is this changing over time? Can you plot this? </li>\n  <li>Are there missing values? Should these rows be deleted?  </li>\n  <li>Which columns of the datasets contain useful information? What kind of categories are there and are they all meaningful?</li>\n  <li>Which crimes occur most often? And near which location?</li>\n  <li>Is there anything you want to explore further or are curious about? Is there any data that you will need for this?</li>      \n  <li>Notice anything odd about the latitude and longitudes? Read here how the data is anonymised: https://data.police.uk/about/.</li>       \n  </ul> \n</div>  ", "cell_type": "markdown", "metadata": {}}, {"source": "# your data exploration (add as many cells as you need)\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# %load https://raw.githubusercontent.com/IBMDeveloperUK/crime-data-workshop/master/answers/answer3.py", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# %load https://raw.githubusercontent.com/IBMDeveloperUK/crime-data-workshop/master/answers/answer3b.py", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# %load https://raw.githubusercontent.com/IBMDeveloperUK/crime-data-workshop/master/answers/answer4.py", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# %load https://raw.githubusercontent.com/IBMDeveloperUK/crime-data-workshop/master/answers/answer5.py", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# %load https://raw.githubusercontent.com/IBMDeveloperUK/crime-data-workshop/master/answers/answer6.py", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "* The number of stop and searches seems to go up. That is something you could investigate further. Is any of the categories increasing? \n* Another interesting question is how the object of search and the outcome are related. Are there types of searches where nothing is found more frequently? \n* In the original files there are also columns of gender, age range and ethnicity. If you want to explore this further you can change the code and re-process the data from this [notebook](https://github.com/IBMDeveloperUK/geopandas-workshop/blob/master/notebooks/prepare-uk-crime-data.ipynb) and use the full dataset.\n* And how could you combine the two datasets?\n\n### Spatial join\n\n> The below solution was found [here](https://gis.stackexchange.com/questions/306674/geopandas-spatial-join-and-count) after googling for 'geopandas count points in polygon'\n\nThe `crs` needs to be the same for both GeoDataFrames. ", "cell_type": "markdown", "metadata": {}}, {"source": "print(boroughs2.crs)\nprint(stop_search.crs)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Add a borough to each point with a spatial join. This will add the `geometry` and other columns from `boroughs2` to the points in `stop_search`. ", "cell_type": "markdown", "metadata": {}}, {"source": "stop_search.crs = boroughs2.crs\ndfsjoin = gpd.sjoin(boroughs2,stop_search) \ndfsjoin.head()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Then aggregate this table by creating a [pivot table](https://jakevdp.github.io/PythonDataScienceHandbook/03.09-pivot-tables.html) where for each borough the number of types each of the categories in `Object of search` are counted. Then drop the pivot level and remove the index, so you can merge this new table back into the `boroughs2` DataFrame.", "cell_type": "markdown", "metadata": {}}, {"source": "dfpivot = pd.pivot_table(dfsjoin,index='code',columns='Object of search',aggfunc={'Object of search':'count'})\ndfpivot.columns = dfpivot.columns.droplevel()\ndfpivot = dfpivot.reset_index()\ndfpivot.head()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "boroughs3 = boroughs2.merge(dfpivot, how='left',on='code')\nboroughs3.head()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Let's make some maps!", "cell_type": "markdown", "metadata": {}}, {"source": "fig, axs = plt.subplots(1, 2, figsize=(20,5))\n\np1=boroughs3.plot(column='Controlled drugs',ax=axs[0],cmap='Blues',legend=True);\naxs[0].set_title('Controlled drugs', fontdict={'fontsize': '12', 'fontweight' : '5'});\n\np2=boroughs3.plot(column='Stolen goods',ax=axs[1], cmap='Reds',legend=True);\naxs[1].set_title('Stolen goods', fontdict={'fontsize': '12', 'fontweight' : '5'});\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "<div class=\"alert alert-success\">\n <b>EXERCISE</b> <br/> \n Explore the data with GeoPandas. Again there are no right or wrong answers, the questions below give you some suggestions at what to look at. <br/> \n   <ul>\n  <li>Improve the above maps. How many arrests are there in each borough? Use the above method but first select only the arrests using the column 'Outcome'. Can you plot this? </li>\n  <li>Are there changes over time? Is there a difference between months? Use `street` and look at Westminster or another borough where the crime rate seems higher. </li>    \n  </ul> \n</div>  ", "cell_type": "markdown", "metadata": {}}, {"source": "# your data exploration (add as many cells as you need)\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# %load https://raw.githubusercontent.com/IBMDeveloperUK/crime-data-workshop/master/answers/answer7.py\ndfsjoin2 = gpd.sjoin(boroughs2,stop_search[stop_search['Outcome'] == 'Arrest']) \ndfpivot2 = pd.pivot_table(dfsjoin2,index='code',columns='Object of search',aggfunc={'Object of search':'count'})\ndfpivot2.columns = dfpivot2.columns.droplevel()\ndfpivot2 = dfpivot2.reset_index()\nboroughs4 = boroughs2.merge(dfpivot2, how='left',on='code')\nboroughs4.head()\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# %load https://raw.githubusercontent.com/IBMDeveloperUK/crime-data-workshop/master/answers/answer8.py", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Hopefully you got an idea of the possibilities with geospatial data now. There is a lot more to explore with this data. Let me know if you find anything interesting! I am on Twitter as @MargrietGr. \n\n### Author\nMargriet Groenendijk is a Data & AI Developer Advocate for IBM. She develops and presents talks and workshops about data science and AI. She is active in the local developer communities through attending, presenting and organising meetups. She has a background in climate science where she\u00a0explored large observational\u00a0datasets of carbon uptake by forests\u00a0during her PhD, and\u00a0global scale weather and climate models as a postdoctoral fellow.\u00a0\n\nCopyright \u00a9 2019 IBM. This notebook and its source code are released under the terms of the MIT License.", "cell_type": "markdown", "metadata": {}}, {"source": "", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3.6", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.6.8", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}